import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import m2cgen as m2c
import joblib

# Configurations
CSV_PATH = "tinyml\pseudo_arc_dataset.csv" 
OUT_HEADER = "tinyml\TinyML_RF.h"
OUT_JOBLIB = "tinyml\TinyML_RF.joblib"

# Must match the feature order
FEATURES = ["spectral_entropy", "thd_pct", "zcv", "v_rms", "i_rms", "temp_c"]
TARGET = "label_arc"

def find_optimal_threshold(model, X_test, y_test):
    print("\n--- Auto-Tuning Safety Threshold ---")
    y_proba = model.predict_proba(X_test)[:, 1] # Probability of Arc
    
    best_threshold = 0.50
    best_fp = float('inf')
    found_zero_fn = False
    
    # Scan range
    thresholds = np.arange(0.10, 0.96, 0.01)
    
    for thresh in thresholds:
        y_pred = (y_proba >= thresh).astype(int)
        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
        
        # Strictly prioritize 0 False Negatives
        if fn == 0:
            found_zero_fn = True
            if fp < best_fp:
                best_fp = fp
                best_threshold = thresh
            elif fp == best_fp:
                # If tied, pick higher threshold (more robust to noise)
                best_threshold = max(best_threshold, thresh)

    # Fallback if no perfect threshold exists
    if not found_zero_fn:
        print("WARNING: No threshold found with 0 False Negatives. Optimizing for F1.")
        best_threshold = 0.5

    print(f"Optimal Safety Threshold Found: {best_threshold:.2f}")
    return best_threshold

def main():
    # Loading Dataset
    print(f"Loading dataset from {CSV_PATH}...")
    try:
        df = pd.read_csv(CSV_PATH)
    except FileNotFoundError:
        print("Error: CSV file not found. Check the path!")
        return

    X = df[FEATURES]
    y = df[TARGET]

    # Split Data for Training and Testing
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    print(f"Training on {len(X_train)} samples, Testing on {len(X_test)} samples.")

    # Grid Search (Optimize Hyperparameters)
    # 
    param_grid = {
        'n_estimators': [30, 50, 80],      
        'max_depth': [8, 10, 12],          
        'min_samples_leaf': [2, 4],        
        'class_weight': ['balanced'],      
        'bootstrap': [True]
    }

    print("\n--- Starting Grid Search ---")
    rf = RandomForestClassifier(random_state=42)
    grid_search = GridSearchCV(
        estimator=rf, 
        param_grid=param_grid, 
        cv=3, 
        scoring='average_precision',
        n_jobs=-1, 
        verbose=1
    )
    grid_search.fit(X_train, y_train)
    
    best_clf = grid_search.best_estimator_
    print(f"\nBest Params: {grid_search.best_params_}")

    # Find the Perfect Threshold
    optimal_threshold = find_optimal_threshold(best_clf, X_test, y_test)

    # Final Verification
    y_proba = best_clf.predict_proba(X_test)[:, 1]
    y_final_pred = (y_proba >= optimal_threshold).astype(int)
    
    print("\n--- FINAL VERIFICATION ---")
    tn, fp, fn, tp = confusion_matrix(y_test, y_final_pred).ravel()
    print(f"Threshold Used: {optimal_threshold:.2f}")
    print(f"True Negatives (Safe):      {tn}")
    print(f"False Positives (Nuisance): {fp}")
    print(f"False Negatives (DANGER):   {fn}  <-- Should be 0")
    print(f"True Positives (Caught):    {tp}")
    print(f"Accuracy: {accuracy_score(y_test, y_final_pred):.4f}")

    # Save Python Model
    joblib.dump(best_clf, OUT_JOBLIB)
    print(f"\nSaved Python model to: {OUT_JOBLIB}")

    # Convert to TinyML Header
    print("Generating C code...")
    c_code = m2c.export_to_c(best_clf, function_name="arc_rf_predict")

    header_content = f"""#pragma once
// Auto-generated by m2cgen from scikit-learn RandomForest
// Generated on: {pd.Timestamp.now()}

// AUTO-TUNED SAFETY THRESHOLD
// If probability of Arc is > this value, we trip.
#define ARC_THRESHOLD {optimal_threshold:.4f}

// Input Feature Order:
// [0] spectral_entropy
// [1] thd_pct
// [2] zcv
// [3] v_rms
// [4] i_rms
// [5] temp_c

#ifdef __cplusplus
extern "C" {{
#endif

// ERROR FIX: m2cgen classifiers return void and fill an output array.
// output[0] = Probability of Normal
// output[1] = Probability of Arc Fault
void arc_rf_predict(double *input, double *output);

#ifdef __cplusplus
}}
#endif

{c_code}
"""
    with open(OUT_HEADER, "w") as f:
        f.write(header_content)

    print(f"Successfully wrote C header to: {OUT_HEADER}")

if __name__ == "__main__":
    main()